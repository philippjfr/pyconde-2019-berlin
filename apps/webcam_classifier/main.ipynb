{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/philippjfr/miniconda3/envs/pyconde2019/lib/python3.7/site-packages/cv2.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libfreetype.6.dylib\n  Referenced from: /Users/philippjfr/miniconda3/envs/pyconde2019/lib/libopencv_freetype.4.1.dylib\n  Reason: Incompatible library version: libopencv_freetype.4.1.dylib requires version 24.0.0 or later, but libfreetype.6.dylib provides version 23.0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-127eb2974c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpanel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mholoviews\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/philippjfr/miniconda3/envs/pyconde2019/lib/python3.7/site-packages/cv2.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libfreetype.6.dylib\n  Referenced from: /Users/philippjfr/miniconda3/envs/pyconde2019/lib/libopencv_freetype.4.1.dylib\n  Reason: Incompatible library version: libopencv_freetype.4.1.dylib requires version 24.0.0 or later, but libfreetype.6.dylib provides version 23.0.0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import codecs\n",
    "import requests\n",
    "import base64\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "import param\n",
    "import PIL\n",
    "import panel as pn\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "\n",
    "from PIL import ImageDraw\n",
    "\n",
    "hv.extension('bokeh')\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetector(param.Parameterized):\n",
    "    \"\"\"\n",
    "    Detects objects in a webcam video stream using OpenCV Tensorflow model.\n",
    "    \"\"\"\n",
    "    \n",
    "    detection_threshold = param.Number(default=0.5, bounds=(0, 1))\n",
    "    \n",
    "    snapshot = param.Action(lambda x: x.param.trigger('snapshot'))\n",
    "\n",
    "    vstream = param.ClassSelector(class_=pn.widgets.VideoStream)\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        if 'vstream' not in params:\n",
    "            params['vstream'] = pn.widgets.VideoStream(width=480, height=360)\n",
    "        super(ObjectDetector, self).__init__(**params)\n",
    "        self._bounds = []\n",
    "        self.cvNet = cv.dnn.readNetFromTensorflow('./ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb',\n",
    "                                                  './ssd_mobilenet_v2_coco_2018_03_29.pbtxt')\n",
    "    \n",
    "    def get_img(self):\n",
    "        base64 = self.vstream.value.split(',')[1]\n",
    "        b = codecs.decode(bytes(base64, 'utf-8'), 'base64')\n",
    "        return PIL.Image.open(BytesIO(b))\n",
    "\n",
    "    def detect_objects(self, img):\n",
    "        cvimg = cv.cvtColor(np.array(img).astype(np.uint8), cv.COLOR_RGB2BGR)\n",
    "        rows = cvimg.shape[0]\n",
    "        cols = cvimg.shape[1]\n",
    "        self.cvNet.setInput(cv.dnn.blobFromImage(cvimg, size=(200, 200), swapRB=True, crop=False))\n",
    "        cvOut = self.cvNet.forward()\n",
    "\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        bounds = []\n",
    "        for detection in cvOut[0,0,:,:]:\n",
    "            score = float(detection[2])\n",
    "            if score > self.detection_threshold:\n",
    "                left = detection[3] * cols\n",
    "                top = detection[4] * rows\n",
    "                right = detection[5] * cols\n",
    "                bottom = detection[6] * rows\n",
    "                bounds.append((left, rows-bottom, right, rows-top))\n",
    "                draw.rectangle([left, bottom, right, top])\n",
    "        return img, bounds\n",
    "\n",
    "    @param.depends('snapshot', watch=True)\n",
    "    def _take_snapshot(self):\n",
    "        self.vstream.snapshot()\n",
    "\n",
    "    @param.depends('vstream.value')\n",
    "    def get_objects(self):\n",
    "        try:\n",
    "            img = self.get_img()\n",
    "        except:\n",
    "            img = np.array([[0]], dtype='uint8')\n",
    "\n",
    "        try:\n",
    "            img, bounds = self.detect_objects(img)\n",
    "        except:\n",
    "            img, bounds = PIL.Image.fromarray(img), []\n",
    "        self._bounds = bounds\n",
    "        return pn.panel(img, width=480, height=360)\n",
    "\n",
    "    @param.output()\n",
    "    def image(self):\n",
    "        return hv.RGB(np.array(self.get_img()), bounds=(0, 0, 640, 480)).opts(\n",
    "            frame_width=640, frame_height=480, xaxis=None, yaxis=None)\n",
    "    \n",
    "    @param.output()\n",
    "    def polygons(self):\n",
    "        return hv.Path([hv.Bounds(b) for b in self._bounds]).opts(\n",
    "            line_color='black', line_width=3, apply_ranges=False, tools=['tap'])\n",
    "    \n",
    "    def panel(self):\n",
    "        row = pn.Row(self.vstream, self.get_objects)\n",
    "        return pn.Row(pn.layout.HSpacer(), pn.Column(self.param.detection_threshold, row, self.param.snapshot), pn.layout.HSpacer())\n",
    "\n",
    "detector = ObjectDetector()\n",
    "\n",
    "detector.panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(param.Parameterized):\n",
    "    \"\"\"\n",
    "    Allows editing and selecting bounding boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    polygons = param.ClassSelector(class_=hv.Path)\n",
    "    \n",
    "    image = param.ClassSelector(class_=hv.Image)\n",
    "        \n",
    "    def panel(self):\n",
    "        self.edit = hv.streams.PolyEdit(source=self.polygons)\n",
    "        self.selection = hv.streams.Selection1D(source=self.polygons)\n",
    "        return pn.Row(pn.layout.HSpacer(), pn.panel(self.image * self.polygons), pn.layout.HSpacer())\n",
    "\n",
    "    @param.output()\n",
    "    def images(self):\n",
    "        return [self.image.select(x=path.range(0), y=path.range(1))\n",
    "                for i, path in enumerate(self.edit.element.split())\n",
    "                if i in self.selection.index]\n",
    "\n",
    "selector = Selector(image=detector.image(), polygons=detector.polygons())\n",
    "\n",
    "selector.panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionAPI(param.Parameterized):\n",
    "    \n",
    "    images = param.List()\n",
    "    \n",
    "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "    GOOGLE_CLOUD_VISION_URL = \"https://vision.googleapis.com/v1/images:annotate\"\n",
    "\n",
    "    @classmethod\n",
    "    def make_request(cls, img):\n",
    "        pimg = PIL.Image.fromarray(img.data)\n",
    "        bio = BytesIO()\n",
    "        pimg.save(bio, 'png')\n",
    "        bio.seek(0)\n",
    "        b64_string = base64.b64encode(bio.read()).decode('utf-8')\n",
    "        body = {\n",
    "            \"requests\": [{\n",
    "                \"image\": {\"content\": b64_string},\n",
    "                \"features\": [{\"type\": \"LABEL_DETECTION\"}]\n",
    "            }]\n",
    "        }\n",
    "        return requests.post(\"%s?key=%s\" % (cls.GOOGLE_CLOUD_VISION_URL, cls.GOOGLE_API_KEY),\n",
    "                             json.dumps(body), headers={'content-type': 'application/json'})\n",
    "    \n",
    "    def panel(self):\n",
    "        panes = []\n",
    "        for img in self.images:\n",
    "            panes.append(pn.panel(PIL.Image.fromarray(img.data), width=300))\n",
    "            panes.append(pd.DataFrame(self.make_request(img).json()['responses'][0]['labelAnnotations'],\n",
    "                                      columns=['description', 'score', 'topicality']))\n",
    "        return pn.Row(pn.layout.HSpacer(), pn.Row(*panes), pn.layout.HSpacer())\n",
    "    \n",
    "VisionAPI(images=selector.images()).panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pn.pipeline.Pipeline()\n",
    "\n",
    "pipeline.add_stage('Detector', ObjectDetector)\n",
    "pipeline.add_stage('Selector', Selector)\n",
    "pipeline.add_stage('Classifier', VisionAPI)\n",
    "\n",
    "layout = pipeline.layout\n",
    "layout.sizing_mode = 'stretch_both'\n",
    "layout.servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
